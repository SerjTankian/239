{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание\n",
    "\n",
    "Домашнее задание номер 1. Про трансфер лернинг.\n",
    "\n",
    "Идея заключается в том, что часто учить большую сеть с нуля для новой задачи не хочется. При этом, первые слои во многих задачах детектируют одни и те же фичи. Значит для решения своей задачи можно взять сетку обученную на похожем датасете, взять ее веса, кроме последнего полносвязного слоя (или нескольких), и дообучить последний слой (или несколько) для своей задачи.\n",
    "\n",
    "В данном задании, в папке ./weighsts лежат веса предобученной сетки для классификации цифр 4 и 8. Предлагается написать код, который переучит эту сетку на любые две другие цифры и сравнить по времени с обучением сети с нуля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем данные, пока выделяем цифры 4 и 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../../6.Intro_to_NN/data/train.csv\")\n",
    "\n",
    "x_all = data[data.columns[1:]].values\n",
    "y_all = data[data.columns[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.logical_or(y_all == 4, y_all == 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = x_all[mask], y_all[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (y == 4).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сетка предобучена на картинках ужатых в 14 на 14 пикселей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (14, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(-1, 28,28)[:, ::2,::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_tr, x_te, y_tr, y_te = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будьте внимательны, если вы используете GPU, все тензоры должны быть так или иначе отправленны туда. Например с помощью метода .cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = torch.from_numpy(x_tr.astype(np.float32)).cuda()\n",
    "x_te = torch.from_numpy(x_te.astype(np.float32)).cuda()\n",
    "y_tr = torch.from_numpy(y_tr.astype(int)).cuda()\n",
    "y_te = torch.from_numpy(y_te.astype(int)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr = x_tr.reshape(x_tr.shape[0], 1, x_tr.shape[1], x_tr.shape[2])\n",
    "x_te = x_te.reshape(x_te.shape[0], 1, x_te.shape[1], x_te.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код для загрузки батчей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_minibatches(x, y, batchsize, shuffle=True):\n",
    "    if shuffle:\n",
    "        indices = np.arange(x.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, x.shape[0] - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield x[excerpt], y[excerpt]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализируем сетку\n",
    "\n",
    "Чтобы это произошло на GPU, в инициализации добавляем .cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(1, 8, (3,3))\n",
    "        self.max_p_1 = nn.MaxPool2d((2,2))\n",
    "        self.conv_2 = nn.Conv2d(8, 16, (3,3))\n",
    "        self.max_p_2 = nn.MaxPool2d((2,2))\n",
    "        self.linear = nn.Linear(64, 2)\n",
    "       \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = F.tanh(x)\n",
    "        x = self.max_p_1(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        \n",
    "        x = self.conv_2(x)\n",
    "        x = F.tanh(x)\n",
    "        x = self.max_p_2(x)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        x = x.reshape(-1, 64)\n",
    "        x = self.linear(x)\n",
    "        x = F.softmax(x, dim = 1)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net().cuda()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка параметров в сеть \n",
    "Загрузить нужно все параметры кроме последнего полносвязного слоя. Его нужно оставить таким, какой был при инициализации.\n",
    "\n",
    "Веса сеток в торче загружаются и сохраняются с помощью так называемого state_dict. Это словарь в котором ключи - названия весов и слоев сетки, а переменные это веса. \n",
    "Для хранения, загрузки и сохранения таких словарей используются функции:\n",
    "- torch.load() - загружает state_dict из файла\n",
    "- torch.save() - сохраняет state_dict в файл\n",
    "И методы самой сетки\n",
    "- net.load_state_dict() - загружает веса в сетку\n",
    "- net.state_dict() - вызвращает веса сетки.\n",
    "\n",
    "Чтобы подгрузить не все веса в сеть, нужно сначала загрузить словарь из файла, затем удалить часть весов из него, потом воспользоваться .load_state_dict(), обратив внимание на аргумент strict. \n",
    "\n",
    "Загрузите нужные веса в сеть:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* YOUR CODE HERE * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Новая задача для сетки\n",
    "\n",
    "Теперь выделите из датасета любые другие цифры или сделайте классификацию всех цифр сразу. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tr_new = * YOUR CODE HERE * \n",
    "x_te_new = * YOUR CODE HERE * \n",
    "y_tr_new = * YOUR CODE HERE * \n",
    "y_te_new = * YOUR CODE HERE * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Заморозка градиенов\n",
    "\n",
    "Мы хотим учить только последний слой сетки и не испортить веса во всех остальных. Значит нужно для всех прдыдущих слоев проставить requires_grad = False. Тогда во время оптимизации градиенты для них не будут считаться, а значит не будет и не нужных изменений.\n",
    "\n",
    "Обратиться к слоям и весам сетки можно разными способами. Например:\n",
    "- net.parameters()\n",
    "- net.*layer_name*.weight и net.*layer_name*.bias\n",
    "\n",
    "Заморозте все слои инициализированной сетки, кроме последнего"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* YOUR CODE HERE *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "\n",
    "Ниже стандартный код для обучения. Дообучите сетку на новой задаче."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "sgd = SGD(net.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    batch_losses = []\n",
    "    for i, (batch_x, batch_y) in enumerate(iterate_minibatches(x_tr[:], y_tr[:], 20)):       \n",
    "        out = net(batch_x)\n",
    "        target = batch_y\n",
    "\n",
    "        sgd.zero_grad()\n",
    "        loss = criterion(out, target)\n",
    "\n",
    "        loss.backward()\n",
    "        sgd.step()\n",
    "        \n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "    train_losses.append(np.mean(batch_losses))\n",
    "    \n",
    "    val_losses.append(criterion(net(x_te), y_te).item())\n",
    "\n",
    "    \n",
    "    display.clear_output(wait=True)\n",
    "    plt.plot(train_losses, label='train')\n",
    "    plt.plot(val_losses, label='val')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ранняя остановка\n",
    "\n",
    "Обучение имеет смысл проводить пока ошибка на тестовом датасете не перестала падать. Критерием такой остановки может служить то, что минимальная ошибка на тестовом сете была достигнута не на последних К эпохах, где К некоторый параметр порядка 5-10.\n",
    "\n",
    "Чтобы удобно учить сетки реализуйте функцию, которая принимает на вход сетку, оптимизатор и датасет, максимальное кол-во эпох, размер батча и длину окна для ранней остановки, затем обучает сеть и возвращает сетку, оптимизатор и массивы с train и test ошибками для каждой эпохи и флажок о том произошел ли early stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_early_stop(net, \n",
    "                     optimizer,\n",
    "                     x_tr, x_te, y_tr, y_te,\n",
    "                     max_epochs,\n",
    "                     batch_size,\n",
    "                     early_stop_window):\n",
    "    *YOUR CODE HERE*\n",
    "    \n",
    "    return net, optimizer, train_losses, val_losses, early_stop_happend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение сеток\n",
    "\n",
    "Теперь обучите сетку инициализированную случайнымми весами и сетку в которой первые слои инициализированы из обученной сетки и нужные градиенты замороженны. Замерьте время обучения. Для этого можно использовать cell magic - особые команды для юпитера, - вам нужна команда %time или %%time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
