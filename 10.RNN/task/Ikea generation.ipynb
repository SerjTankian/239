{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../task/data/ikea\") as f:\n",
    "    lines = [x[:-1] for x in f.readlines() if len(x[:-1]) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elongate_name(name):\n",
    "    return name + '_'*(12 - len(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = np.array(list(map(elongate_name,lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ABSORB______', 'ADMETE______', 'AGAM________', ...,\n",
       "       'ÖRTER_______', 'ÖSTERBYMO___', 'ÖSTERÖ______'], dtype='<U12')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = set([char for name in lines for char in name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'A': 829,\n",
       "         'B': 230,\n",
       "         'S': 551,\n",
       "         'O': 348,\n",
       "         'R': 671,\n",
       "         '_': 8309,\n",
       "         'D': 300,\n",
       "         'M': 287,\n",
       "         'E': 560,\n",
       "         'T': 502,\n",
       "         'G': 295,\n",
       "         'N': 556,\n",
       "         'Y': 109,\n",
       "         'I': 494,\n",
       "         'K': 355,\n",
       "         'L': 617,\n",
       "         'U': 215,\n",
       "         'X': 18,\n",
       "         'Å': 75,\n",
       "         'P': 167,\n",
       "         'V': 182,\n",
       "         'Ä': 125,\n",
       "         'F': 144,\n",
       "         'J': 135,\n",
       "         'H': 100,\n",
       "         'Ö': 107,\n",
       "         'C': 48,\n",
       "         'Z': 2,\n",
       "         'W': 1})"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter([char for name in lines for char in name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_to_num = dict(zip(sorted(letters), np.arange(len(letters))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find letter index from all_letters, e.g. \"a\" = 0\n",
    "def letterToIndex(letter):\n",
    "    return sym_to_num[letter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letterToTensor(letter, n_letters = len(letters)):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lineToTensor(line, n_letters = len(letters)):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7],\n",
       "        [ 4],\n",
       "        [11],\n",
       "        [11]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineToTensor('HELL').argmax(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "\n",
    "    def __init__(self, inp_dim, hidden_dim, vocab_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(inp_dim, hidden_dim, num_layers = 3)\n",
    "\n",
    "        self.out2prediction = nn.Linear(hidden_dim, vocab_size)\n",
    "        \n",
    "        self.hidden = self.init_hidden()\n",
    "\n",
    "    def init_hidden(self, batch_size = BATCH_SIZE):\n",
    "        # Before we've done anything, we dont have any hidden state.\n",
    "        # Refer to the Pytorch documentation to see exactly\n",
    "        # why they have this dimensionality.\n",
    "        # The axes semantics are (num_layers, minibatch_size, hidden_dim)\n",
    "        return (torch.zeros(3, batch_size, self.hidden_dim),\n",
    "                torch.zeros(3, batch_size, self.hidden_dim))\n",
    "\n",
    "    def logits(self, sentence, batch_size = BATCH_SIZE):\n",
    "        lstm_out, self.hidden = self.lstm(sentence.reshape(len(sentence), batch_size, -1), self.hidden)\n",
    "        \n",
    "        out = self.out2prediction(lstm_out)\n",
    "        return out\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        out = self.logits(sentence)\n",
    "        out = out.reshape(-1, out.shape[2])\n",
    "        return F.log_softmax(out, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "INP_DIM = len(letters)\n",
    "HIDDEN_DIM = 16\n",
    "BATCH_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_minibatch(data, do_return = 0):\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    data = data[: len(data) // BATCH_SIZE * BATCH_SIZE]\n",
    "    for names in np.array_split(data, data.shape[0] / BATCH_SIZE):\n",
    "        #(len, batch, n_letters)\n",
    "        inp = [lineToTensor(name) for name in names]\n",
    "        inp = torch.cat(inp, dim = 1)\n",
    "        #print(inp.shape)\n",
    "        \n",
    "        target = inp.argmax(2).reshape(-1)\n",
    "        \n",
    "        yield inp, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = get_minibatch(lines[:10], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [x for x in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 10, 29])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.1728, -3.3560, -3.5930,  ..., -3.1822, -3.5951, -3.1344],\n",
       "        [-3.1729, -3.3566, -3.5920,  ..., -3.1812, -3.5953, -3.1346],\n",
       "        [-3.1720, -3.3557, -3.5938,  ..., -3.1818, -3.5953, -3.1340],\n",
       "        ...,\n",
       "        [-3.1465, -3.3668, -3.5911,  ..., -3.1594, -3.6214, -3.1494],\n",
       "        [-3.1468, -3.3669, -3.5905,  ..., -3.1597, -3.6214, -3.1500],\n",
       "        [-3.1440, -3.3667, -3.5925,  ..., -3.1594, -3.6227, -3.1486]],\n",
       "       grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(INP_DIM, HIDDEN_DIM, INP_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(29, 16, num_layers=3)\n",
       "  (out2prediction): Linear(in_features=16, out_features=29, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.hidden = model.init_hidden(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0332, 0.0335, 0.0343, 0.0270, 0.0336, 0.0285, 0.0345, 0.0352, 0.0360,\n",
       "         0.0308, 0.0453, 0.0381, 0.0366, 0.0351, 0.0298, 0.0429, 0.0327, 0.0262,\n",
       "         0.0376, 0.0384, 0.0352, 0.0348, 0.0280, 0.0382, 0.0323, 0.0430, 0.0279,\n",
       "         0.0384, 0.0327],\n",
       "        [0.0332, 0.0335, 0.0343, 0.0271, 0.0336, 0.0285, 0.0346, 0.0352, 0.0361,\n",
       "         0.0308, 0.0453, 0.0381, 0.0367, 0.0350, 0.0298, 0.0429, 0.0327, 0.0262,\n",
       "         0.0376, 0.0384, 0.0352, 0.0349, 0.0280, 0.0382, 0.0323, 0.0430, 0.0279,\n",
       "         0.0384, 0.0327],\n",
       "        [0.0332, 0.0335, 0.0343, 0.0271, 0.0336, 0.0285, 0.0346, 0.0352, 0.0361,\n",
       "         0.0308, 0.0453, 0.0381, 0.0367, 0.0349, 0.0298, 0.0429, 0.0328, 0.0262,\n",
       "         0.0376, 0.0384, 0.0352, 0.0349, 0.0280, 0.0381, 0.0322, 0.0430, 0.0279,\n",
       "         0.0385, 0.0327],\n",
       "        [0.0332, 0.0335, 0.0343, 0.0271, 0.0335, 0.0285, 0.0347, 0.0352, 0.0361,\n",
       "         0.0308, 0.0453, 0.0381, 0.0367, 0.0349, 0.0297, 0.0429, 0.0328, 0.0262,\n",
       "         0.0375, 0.0384, 0.0352, 0.0349, 0.0280, 0.0381, 0.0322, 0.0430, 0.0279,\n",
       "         0.0385, 0.0327],\n",
       "        [0.0332, 0.0335, 0.0343, 0.0271, 0.0335, 0.0285, 0.0347, 0.0352, 0.0361,\n",
       "         0.0308, 0.0454, 0.0380, 0.0367, 0.0349, 0.0297, 0.0429, 0.0328, 0.0262,\n",
       "         0.0375, 0.0384, 0.0351, 0.0349, 0.0280, 0.0381, 0.0322, 0.0430, 0.0279,\n",
       "         0.0385, 0.0328],\n",
       "        [0.0332, 0.0335, 0.0343, 0.0271, 0.0336, 0.0285, 0.0346, 0.0352, 0.0361,\n",
       "         0.0308, 0.0454, 0.0380, 0.0367, 0.0349, 0.0297, 0.0429, 0.0328, 0.0262,\n",
       "         0.0376, 0.0384, 0.0352, 0.0349, 0.0280, 0.0382, 0.0322, 0.0430, 0.0279,\n",
       "         0.0385, 0.0327],\n",
       "        [0.0332, 0.0335, 0.0343, 0.0270, 0.0336, 0.0285, 0.0346, 0.0352, 0.0360,\n",
       "         0.0308, 0.0454, 0.0381, 0.0366, 0.0350, 0.0297, 0.0429, 0.0327, 0.0262,\n",
       "         0.0376, 0.0384, 0.0352, 0.0349, 0.0280, 0.0382, 0.0323, 0.0430, 0.0279,\n",
       "         0.0384, 0.0327],\n",
       "        [0.0332, 0.0335, 0.0343, 0.0270, 0.0336, 0.0285, 0.0345, 0.0352, 0.0360,\n",
       "         0.0308, 0.0454, 0.0381, 0.0366, 0.0350, 0.0297, 0.0429, 0.0327, 0.0262,\n",
       "         0.0376, 0.0384, 0.0352, 0.0349, 0.0280, 0.0382, 0.0323, 0.0430, 0.0279,\n",
       "         0.0384, 0.0327],\n",
       "        [0.0332, 0.0335, 0.0343, 0.0270, 0.0336, 0.0285, 0.0345, 0.0352, 0.0360,\n",
       "         0.0308, 0.0454, 0.0381, 0.0366, 0.0350, 0.0297, 0.0429, 0.0327, 0.0262,\n",
       "         0.0376, 0.0384, 0.0352, 0.0349, 0.0280, 0.0382, 0.0323, 0.0430, 0.0279,\n",
       "         0.0384, 0.0327],\n",
       "        [0.0332, 0.0335, 0.0343, 0.0270, 0.0336, 0.0285, 0.0345, 0.0352, 0.0360,\n",
       "         0.0308, 0.0454, 0.0381, 0.0366, 0.0350, 0.0297, 0.0429, 0.0326, 0.0262,\n",
       "         0.0376, 0.0384, 0.0352, 0.0349, 0.0280, 0.0383, 0.0323, 0.0430, 0.0279,\n",
       "         0.0384, 0.0327],\n",
       "        [0.0332, 0.0335, 0.0343, 0.0270, 0.0336, 0.0286, 0.0345, 0.0352, 0.0360,\n",
       "         0.0308, 0.0454, 0.0381, 0.0366, 0.0351, 0.0298, 0.0429, 0.0326, 0.0262,\n",
       "         0.0376, 0.0384, 0.0353, 0.0349, 0.0280, 0.0383, 0.0324, 0.0430, 0.0279,\n",
       "         0.0384, 0.0327],\n",
       "        [0.0332, 0.0335, 0.0343, 0.0270, 0.0336, 0.0286, 0.0345, 0.0352, 0.0360,\n",
       "         0.0308, 0.0453, 0.0381, 0.0366, 0.0351, 0.0298, 0.0429, 0.0327, 0.0262,\n",
       "         0.0376, 0.0384, 0.0353, 0.0348, 0.0280, 0.0383, 0.0324, 0.0430, 0.0279,\n",
       "         0.0384, 0.0327]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(model.logits(lineToTensor(lines[2]), 1).reshape(-1, 29), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K', 'K']"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[num_to_sym[x] for x in model.logits(lineToTensor(lines[0]), 1).reshape(-1, len(letters)).argmax(1).numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPARSAM_____'"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 29])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd49f7951a1941c588916b8cb345e240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.4244022369384766\n",
      "-2.406557083129883\n",
      "-2.3668346405029297\n",
      "-2.318957805633545\n",
      "-2.3057732582092285\n",
      "-2.2864599227905273\n",
      "-2.2506613731384277\n",
      "-2.2260191440582275\n",
      "-2.2094650268554688\n",
      "-2.180917739868164\n",
      "-2.161099910736084\n",
      "-2.1347203254699707\n",
      "-2.1423041820526123\n",
      "-2.1405467987060547\n",
      "-2.139617681503296\n",
      "-2.139402389526367\n",
      "-2.1163156032562256\n",
      "-2.1009819507598877\n",
      "-2.094451427459717\n",
      "-2.0799858570098877\n",
      "-2.0738799571990967\n",
      "-2.069404363632202\n",
      "-2.085393190383911\n",
      "-2.0740694999694824\n",
      "-2.0875582695007324\n",
      "-2.0975582599639893\n",
      "-2.126966714859009\n",
      "-2.152482748031616\n",
      "-2.1663498878479004\n",
      "-2.186352252960205\n",
      "-2.2269363403320312\n",
      "-2.246551513671875\n",
      "-2.2688302993774414\n",
      "-2.313317060470581\n",
      "-2.3613312244415283\n",
      "-2.4007534980773926\n",
      "-2.4318346977233887\n",
      "-2.4598097801208496\n",
      "-2.504549980163574\n",
      "-2.539842367172241\n",
      "-2.557931423187256\n",
      "-2.5816328525543213\n",
      "-2.608647346496582\n",
      "-2.641688108444214\n",
      "-2.662412643432617\n",
      "-2.6992027759552\n",
      "-2.735395669937134\n",
      "-2.768686056137085\n",
      "-2.7720184326171875\n",
      "-2.829505681991577\n",
      "-2.832099199295044\n",
      "-2.8411169052124023\n",
      "-2.8413784503936768\n",
      "-2.8334195613861084\n",
      "-2.845996379852295\n",
      "-2.8727047443389893\n",
      "-2.8822364807128906\n",
      "-2.896200180053711\n",
      "-2.9079716205596924\n",
      "-2.891904354095459\n",
      "-2.8916125297546387\n",
      "-2.88242506980896\n",
      "-2.8617167472839355\n",
      "-2.865888833999634\n",
      "-2.8276829719543457\n",
      "-2.795217990875244\n",
      "-2.768031120300293\n",
      "-2.723569869995117\n",
      "-2.7032811641693115\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-312-b532fe3cf861>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for i, (inp, target) in enumerate(tqdm_notebook(get_minibatch(lines))):\n",
    "        model.hidden = model.init_hidden()\n",
    "        \n",
    "        out = model(inp)\n",
    "        \n",
    "        loss = criterion(out[:], target[:])\n",
    "        loss.backward()\n",
    "        print(model.lstm.all_weights[0][0].grad.sum().item())\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    print(\"_________________\", epoch_loss)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KNYCK'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_sym = {}\n",
    "\n",
    "for item in sym_to_num.items():\n",
    "    num_to_sym[item[1]] = item[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_to_num['S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[5, 10, -1]' is invalid for input of size 145",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-218-dc24dc4d8bde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlineToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KNYCK\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-200-348f5039f8cd>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-200-348f5039f8cd>\u001b[0m in \u001b[0;36mlogits\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout2prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[5, 10, -1]' is invalid for input of size 145"
     ]
    }
   ],
   "source": [
    "np.exp(model(lineToTensor(\"KNYCK\")).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_to_num = {'h':0, 'e':1, 'l':2, 'o':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'h': 0, 'e': 1, 'l': 2, 'o': 3}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_to_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_to_num['e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.6599e-24, 1.0000e+00, 6.0662e-29, 5.0154e-29],\n",
       "        [1.0000e+00, 1.5718e-17, 5.0758e-27, 3.8477e-27],\n",
       "        [3.6460e-24, 1.0000e+00, 6.0311e-29, 4.9855e-29],\n",
       "        [1.0000e+00, 1.5742e-17, 5.0698e-27, 3.8429e-27],\n",
       "        [3.6413e-24, 1.0000e+00, 6.0183e-29, 4.9746e-29],\n",
       "        [1.0000e+00, 1.5750e-17, 5.0673e-27, 3.8409e-27],\n",
       "        [3.6394e-24, 1.0000e+00, 6.0127e-29, 4.9700e-29],\n",
       "        [1.0000e+00, 1.5754e-17, 5.0660e-27, 3.8399e-27]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(lineToTensor(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineToTensor('hehehe').argmax(2).long().squeeze()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., 0.]],\n",
       "\n",
       "        [[1., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 1., 0., 0.]]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineToTensor('hehehe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "    print(tag_scores)\n",
    "\n",
    "for epoch in range(300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Also, we need to clear out the hidden state of the LSTM,\n",
    "        # detaching it from its history on the last instance.\n",
    "        model.hidden = model.init_hidden()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "    # for word i. The predicted tag is the maximum scoring tag.\n",
    "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "    # since 0 is index of the maximum value of row 1,\n",
    "    # 1 is the index of maximum value of row 2, etc.\n",
    "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise: Augmenting the LSTM part-of-speech tagger with character-level features\n",
    "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "In the example above, each word had an embedding, which served as the\n",
    "inputs to our sequence model. Let's augment the word embeddings with a\n",
    "representation derived from the characters of the word. We expect that\n",
    "this should help significantly, since character-level information like\n",
    "affixes have a large bearing on part-of-speech. For example, words with\n",
    "the affix *-ly* are almost always tagged as adverbs in English.\n",
    "\n",
    "To do this, let $c_w$ be the character-level representation of\n",
    "word $w$. Let $x_w$ be the word embedding as before. Then\n",
    "the input to our sequence model is the concatenation of $x_w$ and\n",
    "$c_w$. So if $x_w$ has dimension 5, and $c_w$\n",
    "dimension 3, then our LSTM should accept an input of dimension 8.\n",
    "\n",
    "To get the character level representation, do an LSTM over the\n",
    "characters of a word, and let $c_w$ be the final hidden state of\n",
    "this LSTM. Hints:\n",
    "\n",
    "* There are going to be two LSTM's in your new model.\n",
    "  The original one that outputs POS tag scores, and the new one that\n",
    "  outputs a character-level representation of each word.\n",
    "* To do a sequence model over characters, you will have to embed characters.\n",
    "  The character embeddings will be the input to the character LSTM.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
