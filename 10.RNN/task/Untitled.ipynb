{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "\n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(3, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out:  tensor([[[-0.0579,  0.2796, -0.0890]]], grad_fn=<CatBackward>)\n",
      "hidden:  (tensor([[[-0.0579,  0.2796, -0.0890]]], grad_fn=<ViewBackward>), tensor([[[-0.2656,  0.3973, -0.4105]]], grad_fn=<ViewBackward>))\n",
      "out:  tensor([[[-0.2075, -0.0041, -0.0028]]], grad_fn=<CatBackward>)\n",
      "hidden:  (tensor([[[-0.2075, -0.0041, -0.0028]]], grad_fn=<ViewBackward>), tensor([[[-0.5567, -0.0086, -0.0059]]], grad_fn=<ViewBackward>))\n",
      "out:  tensor([[[-0.3246, -0.1086, -0.0493]]], grad_fn=<CatBackward>)\n",
      "hidden:  (tensor([[[-0.3246, -0.1086, -0.0493]]], grad_fn=<ViewBackward>), tensor([[[-0.7477, -0.1442, -0.1625]]], grad_fn=<ViewBackward>))\n",
      "out:  tensor([[[-0.2259, -0.0476, -0.0552]]], grad_fn=<CatBackward>)\n",
      "hidden:  (tensor([[[-0.2259, -0.0476, -0.0552]]], grad_fn=<ViewBackward>), tensor([[[-0.8860, -0.0926, -0.1202]]], grad_fn=<ViewBackward>))\n",
      "out:  tensor([[[-0.2878, -0.1108,  0.1416]]], grad_fn=<CatBackward>)\n",
      "hidden:  (tensor([[[-0.2878, -0.1108,  0.1416]]], grad_fn=<ViewBackward>), tensor([[[-0.9335, -0.3006,  0.2212]]], grad_fn=<ViewBackward>))\n"
     ]
    }
   ],
   "source": [
    "for i in inputs:\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "    print(\"out: \", out)\n",
    "    print(\"hidden: \", hidden)\n",
    "\n",
    "# alternatively, we can do the entire sequence all at once.\n",
    "# the first value returned by LSTM is all of the hidden states throughout\n",
    "# the sequence. the second is just the most recent hidden state\n",
    "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
    "# by passing it as an argument  to the lstm at a later time\n",
    "# Add the extra 2nd dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.3282,  0.0192, -0.0195]],\n",
      "\n",
      "        [[-0.2797, -0.0302,  0.0073]],\n",
      "\n",
      "        [[-0.3952, -0.1122, -0.0519]],\n",
      "\n",
      "        [[-0.2514, -0.0444, -0.0612]],\n",
      "\n",
      "        [[-0.3150, -0.1087,  0.1378]]], grad_fn=<CatBackward>)\n",
      "(tensor([[[-0.3150, -0.1087,  0.1378]]], grad_fn=<ViewBackward>), tensor([[[-1.1161, -0.2957,  0.2149]]], grad_fn=<ViewBackward>))\n"
     ]
    }
   ],
   "source": [
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # clean out hidden state\n",
    "out, hidden = lstm(inputs, hidden)\n",
    "print(out)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Hello'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.zeros((5,1,4), dtype=torch.long)\n",
    "inp[0][0][0] = 1\n",
    "inp[1][0][1] = 1\n",
    "inp[2][0][2] = 1\n",
    "inp[3][0][2] = 1\n",
    "inp[4][0][3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(4, 4)  # Input dim is 3, output dim is 3\n",
    "hidden = (torch.randn(1, 1, 4),\n",
    "          torch.randn(1, 1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, hidden = lstm(inp.float(), hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(out.reshape(5,4), inp.argmax(2)[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3652, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0096, -0.0018, -0.0053, -0.0020],\n",
       "        [ 0.0034, -0.0090, -0.0023,  0.0008],\n",
       "        [-0.0007,  0.0074,  0.0100, -0.0022],\n",
       "        [-0.0037,  0.0036,  0.0027, -0.0068],\n",
       "        [-0.0005, -0.0037, -0.0077, -0.0017],\n",
       "        [ 0.0022,  0.0112, -0.0024, -0.0007],\n",
       "        [ 0.0010,  0.0031,  0.0104, -0.0014],\n",
       "        [-0.0044, -0.0033,  0.0022, -0.0051],\n",
       "        [-0.0099,  0.0156,  0.0264,  0.0018],\n",
       "        [-0.0065, -0.0243,  0.0415,  0.0102],\n",
       "        [-0.0004, -0.0114, -0.0606,  0.0030],\n",
       "        [ 0.0069,  0.0108,  0.0182, -0.0246],\n",
       "        [ 0.0227, -0.0027, -0.0081, -0.0063],\n",
       "        [-0.0062,  0.0038, -0.0015, -0.0001],\n",
       "        [-0.0025, -0.0006,  0.0323, -0.0058],\n",
       "        [-0.0050,  0.0023,  0.0113, -0.0153]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.all_weights[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
